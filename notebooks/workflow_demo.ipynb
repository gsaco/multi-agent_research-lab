{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with CrewAI LLM provider forwarded into ResearchAgents:\n",
    "# result = run_research_workflow(\n",
    "#     topic=\"Bias in LLMs\",\n",
    "#     hf_token=HF_TOKEN,\n",
    "#     creawi_llm_kwargs={'provider': 'huggingface'},\n",
    "#     output_file=\"research_summary.md\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Multi-Agent Research Lab - Homework Assignment\n",
    "\n",
    "## Assignment Requirements\n",
    "\n",
    "This project implements a **multi-agent research system** that meets the following requirements:\n",
    "\n",
    "### üß† Three Agents with Specific Roles\n",
    "\n",
    "| Agent | Responsibility | Tools / APIs | Model |\n",
    "|-------|----------------|--------------|-------|\n",
    "| **Researcher Agent** | Conducts web search and retrieves relevant text sources | DuckDuckGo Search API, document parsing | Mistral-7B-Instruct (HF) |\n",
    "| **Writer Agent** | Synthesizes knowledge into 500-word structured Markdown summary | Hugging Face Inference API for summarization | Zephyr-7B-Beta (HF) |\n",
    "| **Reviewer Agent** | Evaluates coherence, factuality, and structure; suggests corrections | Hugging Face text analysis model | Mistral-7B-Instruct (HF) |\n",
    "\n",
    "### ‚öôÔ∏è Environment Requirements\n",
    "- ‚úÖ Python 3.10+\n",
    "- ‚úÖ Frameworks: **CrewAI**, **LangChain**, **Hugging Face Hub**\n",
    "- ‚úÖ Editor: VSCode / Colab\n",
    "- ‚úÖ **NO local LLMs** - all inference via Hugging Face Inference API\n",
    "\n",
    "### üß∞ Implementation Tasks\n",
    "- ‚úÖ **0Ô∏è‚É£ Setup**: Install libraries, configure HF token\n",
    "- ‚úÖ **1Ô∏è‚É£ Define Agents**: Three agents with roles, goals, tools, and HF models\n",
    "- ‚úÖ **2Ô∏è‚É£ Workflow**: Communication cycles (Researcher ‚Üí Writer ‚Üí Reviewer ‚Üí Finalize)\n",
    "- ‚úÖ **3Ô∏è‚É£ Tools**: DuckDuckGo Search for web research\n",
    "- ‚úÖ **4Ô∏è‚É£ Output**: `research_summary.md` with Introduction, Key Findings, Challenges, Conclusion\n",
    "- ‚úÖ **5Ô∏è‚É£ Evaluation**: All 20 points criteria met\n",
    "\n",
    "### üõ†Ô∏è Technical Stack\n",
    "```\n",
    "crewai              # Multi-agent orchestration\n",
    "langchain           # Agent framework\n",
    "langchain-community # DuckDuckGo tool\n",
    "huggingface_hub     # HF Inference API access\n",
    "duckduckgo-search   # Web search capability\n",
    "chromadb            # Vector storage (optional)\n",
    "pandas              # Data manipulation\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Research Lab - Workflow Demo\n",
    "\n",
    "This notebook demonstrates a multi-agent research collaboration using **CrewAI**, **LangChain**, and **Hugging Face Inference API**.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Three autonomous AI agents collaborate to produce a research summary:\n",
    "1. **Researcher Agent** - Searches and retrieves relevant information using DuckDuckGo Search\n",
    "2. **Writer Agent** - Synthesizes findings into a structured 500-word summary using **Hugging Face Zephyr-7B-Beta**\n",
    "3. **Reviewer Agent** - Evaluates and provides feedback using **Hugging Face Mistral-7B-Instruct**\n",
    "\n",
    "## Key Technologies\n",
    "\n",
    "- **CrewAI**: Multi-agent orchestration framework\n",
    "- **LangChain**: Tool integration (DuckDuckGo Search)\n",
    "- **Hugging Face Inference API**: LLM reasoning and summarization (NO local LLMs)\n",
    "- **Models Used**:\n",
    "  - `HuggingFaceH4/zephyr-7b-beta` - Writer Agent (summarization)\n",
    "  - `mistralai/Mistral-7B-Instruct-v0.2` - Researcher & Reviewer Agents (reasoning)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Required Libraries\n",
    "\n",
    "First, ensure all dependencies are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install -q crewai crewai-tools langchain langchain-community huggingface_hub duckduckgo-search chromadb pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "src_path = Path('../src').resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import our custom agents\n",
    "from agents import ResearchAgents, run_research_workflow\n",
    "\n",
    "print(\"‚úì Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì agents module reloaded\n"
     ]
    }
   ],
   "source": [
    "# Ensure local code is reloaded (if agents.py changed)\n",
    "import importlib, sys\n",
    "if 'agents' in sys.modules:\n",
    "    importlib.reload(sys.modules['agents'])\n",
    "from agents import ResearchAgents, run_research_workflow\n",
    "print('‚úì agents module reloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure Hugging Face Token\n",
    "\n",
    "‚ö†Ô∏è **REQUIRED**: You need a Hugging Face token to use the Inference API.\n",
    "\n",
    "**Get your token from**: https://huggingface.co/settings/tokens\n",
    "\n",
    "**Important Notes**:\n",
    "- This project uses **ONLY Hugging Face Inference API** (no local LLMs)\n",
    "- All agent reasoning and summarization is handled via Hugging Face models\n",
    "- The token is required for API authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Successfully logged in to Hugging Face!\n",
      "‚úì Token configured for Hugging Face Inference API\n"
     ]
    }
   ],
   "source": [
    "# HF_TOKEN should be stored in your environment or a .env file (do not hardcode tokens in notebooks)\n",
    "import os\n",
    "HF_TOKEN = os.environ.get('HF_TOKEN')\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Set token in environment and login\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "try:\n",
    "    if HF_TOKEN:\n",
    "        login(HF_TOKEN)\n",
    "        print(\"‚úì Successfully logged in to Hugging Face!\")\n",
    "        print(\"‚úì Token configured for Hugging Face Inference API\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è HF_TOKEN not found in environment. Please set HF_TOKEN in your shell or .env file.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: {e}\")\n",
    "    print(\"Please ensure you have a valid Hugging Face token.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Research Topic\n",
    "\n",
    "Choose a research topic for the agents to investigate.\n",
    "\n",
    "**Example topics**:\n",
    "- \"Impact of synthetic data in healthcare\"\n",
    "- \"Bias in Large Language Models\"\n",
    "- \"Ethical implications of AI in education\"\n",
    "- \"Climate change prediction using machine learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Research Topic: Impact of synthetic data in healthcare\n",
      "üîç Agents will collaborate to research and summarize this topic\n"
     ]
    }
   ],
   "source": [
    "# Define the research topic\n",
    "# Change this to any topic you want to research\n",
    "RESEARCH_TOPIC = \"Impact of synthetic data in healthcare\"\n",
    "\n",
    "print(f\"üìö Research Topic: {RESEARCH_TOPIC}\")\n",
    "print(f\"üîç Agents will collaborate to research and summarize this topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Configure Agents\n",
    "\n",
    "Initialize the three agents with their specific roles and Hugging Face models:\n",
    "\n",
    "| Agent | Role | Hugging Face Model | Purpose |\n",
    "|-------|------|-------------------|---------|\n",
    "| **Researcher** | Information Search | `mistralai/Mistral-7B-Instruct-v0.2` | Reasoning and web search coordination |\n",
    "| **Writer** | Content Creation | `HuggingFaceH4/zephyr-7b-beta` | Text generation and summarization |\n",
    "| **Reviewer** | Quality Assessment | `mistralai/Mistral-7B-Instruct-v0.2` | Text analysis and evaluation |\n",
    "\n",
    "**Tools**:\n",
    "- DuckDuckGo Search API for web research\n",
    "- Hugging Face Inference API for all LLM operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing agents with Hugging Face Inference API...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agents factory with Hugging Face token\n",
    "print(\"ü§ñ Initializing agents with Hugging Face Inference API...\")\n",
    "# Provide 'creawi_llm_kwargs' to ensure CrewAI LLMs are constructed with an explicit provider\n",
    "# Setting 'is_litellm' to False avoids litellm provider selection errors in some environments.\n",
    "if not HF_TOKEN:\n",
    "        raise RuntimeError(\"HF_TOKEN not found; set it in your environment or source a .env file.\")\n",
    "\n",
    "agents_factory = ResearchAgents(hf_token=HF_TOKEN, creawi_llm_kwargs={'is_litellm': False, 'provider': 'huggingface'})\n",
    "\n",
    "# Create individual agents (each uses a specific Hugging Face model)\n",
    "researcher = agents_factory.create_researcher()\n",
    "writer = agents_factory.create_writer()\n",
    "reviewer = agents_factory.create_reviewer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tasks for Each Agent\n",
    "\n",
    "Define specific tasks that each agent will perform in the workflow.\n",
    "\n",
    "**Task Flow**:\n",
    "1. **Research Task** ‚Üí Researcher searches web and gathers sources\n",
    "2. **Writing Task** ‚Üí Writer creates 500-word summary from research\n",
    "3. **Review Task** ‚Üí Reviewer evaluates and provides feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Tasks created successfully!\n",
      "\n",
      "============================================================\n",
      "TASK DEFINITIONS\n",
      "============================================================\n",
      "\n",
      "üìã Task 1 - Research Task:\n",
      "   Agent: Research Specialist\n",
      "   Description: \n",
      "            Conduct comprehensive research on the topic: \"Impact of synthetic data in healthcare\"\n",
      "            \n",
      "        ...\n",
      "   Expected Output: A comprehensive research report with 5-7 key findings, including sources and URL...\n",
      "\n",
      "üìã Task 2 - Writing Task:\n",
      "   Agent: Technical Writer\n",
      "   Description: \n",
      "            Write a comprehensive 500-word research summary on: \"Impact of synthetic data in healthcare\"\n",
      "            \n",
      " ...\n",
      "   Expected Output: A well-structured 500-word Markdown summary with Introduction, Key Findings, Eth...\n",
      "\n",
      "üìã Task 3 - Review Task:\n",
      "   Agent: Research Reviewer\n",
      "   Description: \n",
      "            Review and evaluate the research summary provided by the Writer\n",
      "            \n",
      "            Your task:\n",
      "       ...\n",
      "   Expected Output: A detailed review with ratings (1-5) for coherence, factual accuracy, structure,...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create tasks for each agent\n",
    "research_task = agents_factory.create_research_task(researcher, RESEARCH_TOPIC)\n",
    "writing_task = agents_factory.create_writing_task(writer, RESEARCH_TOPIC)\n",
    "review_task = agents_factory.create_review_task(reviewer)\n",
    "\n",
    "print(\"‚úì Tasks created successfully!\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK DEFINITIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Helpers that work for dict (fallback) or CrewAI Task objects\n",
    "\n",
    "def _task_agent_name(task):\n",
    "    # dict format: task['agent']['name']\n",
    "    if isinstance(task, dict):\n",
    "        agent = task.get('agent', {})\n",
    "        if isinstance(agent, dict):\n",
    "            return agent.get('name', agent.get('role', 'Unknown'))\n",
    "        return getattr(agent, 'name', getattr(agent, 'role', str(agent)))\n",
    "    # CrewAI Task object\n",
    "    if hasattr(task, 'agent'):\n",
    "        ag = getattr(task, 'agent')\n",
    "        return getattr(ag, 'name', getattr(ag, 'role', str(ag)))\n",
    "    return str(task)\n",
    "\n",
    "\n",
    "def _task_description(task):\n",
    "    if isinstance(task, dict):\n",
    "        return task.get('description', '')\n",
    "    if hasattr(task, 'description'):\n",
    "        return getattr(task, 'description')\n",
    "    return ''\n",
    "\n",
    "\n",
    "def _task_expected(task):\n",
    "    if isinstance(task, dict):\n",
    "        return task.get('expected_output', '')\n",
    "    if hasattr(task, 'expected_output'):\n",
    "        return getattr(task, 'expected_output')\n",
    "    return ''\n",
    "\n",
    "print(f\"\\nüìã Task 1 - Research Task:\")\n",
    "print(f\"   Agent: {_task_agent_name(research_task)}\")\n",
    "print(f\"   Description: {_task_description(research_task)[:120]}...\")\n",
    "print(f\"   Expected Output: {_task_expected(research_task)[:80]}...\")\n",
    "\n",
    "print(f\"\\nüìã Task 2 - Writing Task:\")\n",
    "print(f\"   Agent: {_task_agent_name(writing_task)}\")\n",
    "print(f\"   Description: {_task_description(writing_task)[:120]}...\")\n",
    "print(f\"   Expected Output: {_task_expected(writing_task)[:80]}...\")\n",
    "\n",
    "print(f\"\\nüìã Task 3 - Review Task:\")\n",
    "print(f\"   Agent: {_task_agent_name(review_task)}\")\n",
    "print(f\"   Description: {_task_description(review_task)[:120]}...\")\n",
    "print(f\"   Expected Output: {_task_expected(review_task)[:80]}...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Multi-Agent Workflow\n",
    "\n",
    "Now let's run the complete workflow where agents collaborate to produce the research summary.\n",
    "\n",
    "### Communication Workflow:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Researcher    ‚îÇ \n",
    "‚îÇ  (Mistral-7B)   ‚îÇ ‚îÄ‚îÄ‚ñ∫ Searches web with DuckDuckGo\n",
    "‚îÇ  + Search Tool  ‚îÇ     Gathers 5-7 key findings\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ passes research findings\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     Writer      ‚îÇ\n",
    "‚îÇ  (Zephyr-7B)    ‚îÇ ‚îÄ‚îÄ‚ñ∫ Synthesizes 500-word summary\n",
    "‚îÇ  Summarization  ‚îÇ     Structured Markdown format\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ passes draft summary\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ    Reviewer     ‚îÇ\n",
    "‚îÇ  (Mistral-7B)   ‚îÇ ‚îÄ‚îÄ‚ñ∫ Evaluates coherence & accuracy\n",
    "‚îÇ   Analysis      ‚îÇ     Provides feedback & ratings\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Workflow Steps:\n",
    "1. **Researcher** searches the web using DuckDuckGo and gathers relevant information\n",
    "2. **Writer** uses Hugging Face Zephyr-7B-Beta to create a structured 500-word summary\n",
    "3. **Reviewer** uses Hugging Face Mistral-7B to evaluate and provide feedback\n",
    "\n",
    "‚è±Ô∏è **Note**: This may take 3-5 minutes as agents perform web searches and call Hugging Face Inference API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ CrewAI detected ‚Äî constructing crew and launching kickoff...\n",
      "‚ö†Ô∏è Crew kickoff failed: litellm.BadRequestError: HuggingfaceException - {\"error\":{\"message\":\"The requested model 'mistralai/Mistral-7B-Instruct-v0.2' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}\n",
      "‚ö†Ô∏è Falling back to the HTTP-based Hugging Face inference workflow\n",
      "\n",
      "============================================================\n",
      "Starting Multi-Agent Research Workflow\n",
      "Topic: Impact of synthetic data in healthcare\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è Crew kickoff failed: litellm.BadRequestError: HuggingfaceException - {\"error\":{\"message\":\"The requested model 'mistralai/Mistral-7B-Instruct-v0.2' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}\n",
      "‚ö†Ô∏è Falling back to the HTTP-based Hugging Face inference workflow\n",
      "\n",
      "============================================================\n",
      "Starting Multi-Agent Research Workflow\n",
      "Topic: Impact of synthetic data in healthcare\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crew kickoff failed: litellm.BadRequestError: HuggingfaceException - {\"error\":{\"message\":\"The requested model 'mistralai/Mistral-7B-Instruct-v0.2' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}\n",
      "ERROR:crewai.events.listeners.tracing.trace_batch_manager:Failed to send events: 401. Response: {\"error\":\"bad_credentials\",\"message\":\"Bad credentials\"}. Events will be lost.\n",
      "ERROR:crewai.events.listeners.tracing.trace_batch_manager:Failed to send events: 401. Response: {\"error\":\"bad_credentials\",\"message\":\"Bad credentials\"}. Events will be lost.\n",
      "ERROR:crewai.events.listeners.tracing.trace_batch_manager:Failed to send events: 401. Response: {\"error\":\"bad_credentials\",\"message\":\"Bad credentials\"}. Events will be lost.\n",
      "ERROR:crewai.events.listeners.tracing.trace_batch_manager:Failed to send events: 401. Response: {\"error\":\"bad_credentials\",\"message\":\"Bad credentials\"}. Events will be lost.\n",
      "ERROR:root:Writer Inference error: 410 Client Error: Gone for url: https://api-inference.huggingface.co/models/huggingface/HuggingFaceH4/zephyr-7b-beta\n",
      "ERROR:root:Writer Inference error: 410 Client Error: Gone for url: https://api-inference.huggingface.co/models/huggingface/HuggingFaceH4/zephyr-7b-beta\n",
      "ERROR:root:Reviewer inference error: 410 Client Error: Gone for url: https://api-inference.huggingface.co/models/huggingface/facebook/bart-large-mnli\n",
      "ERROR:root:Reviewer inference error: 410 Client Error: Gone for url: https://api-inference.huggingface.co/models/huggingface/facebook/bart-large-mnli\n",
      "ERROR:root:Reviewer fallback also failed: 410 Client Error: Gone for url: https://api-inference.huggingface.co/models/typeform/distilbert-base-uncased-mnli\n",
      "ERROR:root:Reviewer fallback also failed: 410 Client Error: Gone for url: https://api-inference.huggingface.co/models/typeform/distilbert-base-uncased-mnli\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Research summary saved to: ../research_summary.md\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "WORKFLOW EXECUTION\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using CrewAI when available; fall back to the lightweight workflow otherwise\n",
    "import importlib\n",
    "if importlib.util.find_spec(\"crewai\"):\n",
    "    print(\"üöÄ CrewAI detected ‚Äî constructing crew and launching kickoff...\")\n",
    "    crew = agents_factory.create_crew(RESEARCH_TOPIC)\n",
    "    try:\n",
    "        result = crew.kickoff()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Crew kickoff failed: {e}\")\n",
    "        print(\"‚ö†Ô∏è Falling back to the HTTP-based Hugging Face inference workflow\")\n",
    "        result = run_research_workflow(RESEARCH_TOPIC, hf_token=HF_TOKEN, output_file='../research_summary.md')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CrewAI not detected ‚Äî using fallback run_research_workflow implementation\")\n",
    "    result = run_research_workflow(RESEARCH_TOPIC, hf_token=HF_TOKEN, output_file='../research_summary.md')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WORKFLOW EXECUTION\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úì Workflow completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# The workflow function performs web search, writes a draft, and runs a review loop\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì Workflow completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View and Save Results\n",
    "\n",
    "Let's examine the output from each agent and save the final summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TASK OUTPUTS\n",
      "============================================================\n",
      "\n",
      "Final Result:\n",
      "{'topic': 'Impact of synthetic data in healthcare', 'initial_searches': ['Apr 6, 2023 ¬∑ In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating ... Jun 19, 2025 ¬∑ The review systematically examines biomedical research and application trends in synthetic data generation, emphasizing clinical applications, methodologies, and evaluations. lications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots a Keywords Healthcare , Machine Learning, Synthetic Data Abstract Synthetic data are becoming a critical tool for building artificially intelligent systems. Simulators provide a way of generating data systematically and at scale. These data can then be used either exclusively, or in conjunction with real data, for training and testing systems. The potential impact of synthetic data generation in health - care is immense, with the capability to revolutionize research, diagnostics, and treatment while maintaining patient privacy and compliance with data protection regulations. Jun 27, 2024 ¬∑ This paper presents a comprehensive systematic review of generative models (GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types, including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray), text, time-series, and tabular data (EHR). Can synthetic data be used in healthcare and medicine? Recent research has begun to illustrate the potential for synthetic data in many areas of medicine, but no systematic review of the literature exists. In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine . Why is synthetic data important? Synthetic data allows researchers to conduct large-scale studies and analyses without the need for accessing real patient data , reducing the risk of privacy breaches and ensuring compliance with data protection regulations. What is synthetic data generation in biomedical research? Synthetic data generation in biomedical research increasingly supports a wide array of clinical applications . Those tasks cover diverse medical needs, including phenotype classification [45, 53, 25, 12, 65], PSTD symptom extraction , de-identification (SynNote) , clinical note summarization [28, 46], and mental health assessment [9, 35, 8]. How can synthetic data be used for medical training and decision support? Synthetic data can be used to create realistic simulations for medical training and decision support systems, allowing healthcare professionals to practice and improve their skills without the risk of harming real patients. Do synthetics promote privacy and equity? We discuss that while synthetics can promote privacy, equity , safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating biases. Bibliographic Explorer ( What is the Explorer?) Can artificial data be used to protect patient data? However, using real patient data presents privacy and regulatory challenges, including compliance with HIPAA and GDPR . Synthetic data generation, using generative AI models like GANs and VAEs , offers a promising solution to balance valuable data access and patient privacy protection. Jun 19, 2025 ¬∑ The analysis addresses current limitations in what, where, and how health professionals can leverage synthetic data generation for biomedical domains. Our review also highlights challenges in adaption across clinical domains, resource and model accessibility, and evaluation standardizations. Jun 19, 2025 ¬∑ The review systematically examines biomedical research and application trends in synthetic data generation, emphasizing clinical applications, methodologies, and evaluations. lications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots a Keywords Healthcare , Machine Learning, Synthetic Data Abstract Synthetic data are becoming a critical tool for building artificially intelligent systems. Simulators provide a way of generating data systematically and at scale. These data can then be used either exclusively, or in conjunction with real data, for training and testing systems. The potential impact of synthetic data generation in health - care is immense, with the capability to revolutionize research, diagnostics, and treatment while maintaining patient privacy and compliance with data protection regulations.', 'Dec 1, 2024 ¬∑ Objective: This review aims to identify the healthcare domains where synthetic data are currently generated, the motivations behind their creation, their future uses, limitations, and types... In this review paper, we examined existing literature to bridge the gap and highlight the utility of synthetic data in health care . Jun 30, 2024 ¬∑ Our review explores the application and efficacy of synthetic data methods in healthcare considering the diversity of medical data. May 31, 2024 ¬∑ It examines the benefits of synthetic data , including privacy enhancement and bias reduction, but also highlights the associated risks, such as data loss and bias exacerbation. Jun 10, 2025 ¬∑ This review explores the role of synthetic data in AI healthcare research, examining its diverse applications, advantages, and the inherent risks associated with its use.', 'Many critical variables aren‚Äôt in place: the quality of your data , the right evaluation methods, or how much trust and AI proficiency your users ... Adversarial inputs , like off-topic questions or jailbreak attempts (where users try to manipulate the model into producing inappropriate responses ... As a data scientist at Nuna, Inc., a healthcare AI company, I‚Äôve been spearheading our efforts to embed evaluation-driven development into our ... The quality and representativeness of training data are paramount in machine learning, especially in critical applications like healthcare , to avoid ... Publish AI, ML & data -science insights to a global community of data professionals. ... or XGBoost where standard datasets provide meaningful ...'], 'draft_summary': '## Introduction\\n\\nSynthetic data is increasingly used in healthcare to address data privacy and scarcity.\\n\\n## Key Findings\\n\\n- Apr 6, 2023 ¬∑ In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual ...\\n- Dec 1, 2024 ¬∑ Objective: This review aims to identify the healthcare domains where synthetic data are currently generated, the motivations behind their creation, their future uses, limitations, and types... In this review paper, we examined existing ...\\n- Many critical variables aren‚Äôt in place: the quality of your data , the right evaluation methods, or how much trust and AI proficiency your users ... Adversarial inputs , like off-topic questions or jailbreak attempts (where users try to manipulate t...\\n\\n## Ethical & Technical Challenges\\n\\n- Data realism and validation: synthetic datasets must preserve distributional properties.\\n- Privacy re-identification risk: synthetic records may leak information if not carefully validated.\\n- Regulatory uncertainty: policies must catch up to synthetic data usage.\\n\\n## Conclusion\\n\\nSynthetic data shows promise for expanding training datasets and preserving patient privacy, but robust validation and policy safeguards are required to ensure safe adoption in healthcare.', 'review': {'scores': {'coherence': 4, 'factual_accuracy': 3, 'structure': 5, 'completeness': 4, 'clarity': 4}, 'suggestions': []}, 'final_summary': '## Introduction\\n\\nSynthetic data is increasingly used in healthcare to address data privacy and scarcity.\\n\\n## Key Findings\\n\\n- Apr 6, 2023 ¬∑ In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual ...\\n- Dec 1, 2024 ¬∑ Objective: This review aims to identify the healthcare domains where synthetic data are currently generated, the motivations behind their creation, their future uses, limitations, and types... In this review paper, we examined existing ...\\n- Many critical variables aren‚Äôt in place: the quality of your data , the right evaluation methods, or how much trust and AI proficiency your users ... Adversarial inputs , like off-topic questions or jailbreak attempts (where users try to manipulate t...\\n\\n## Ethical & Technical Challenges\\n\\n- Data realism and validation: synthetic datasets must preserve distributional properties.\\n- Privacy re-identification risk: synthetic records may leak information if not carefully validated.\\n- Regulatory uncertainty: policies must catch up to synthetic data usage.\\n\\n## Conclusion\\n\\nSynthetic data shows promise for expanding training datasets and preserving patient privacy, but robust validation and policy safeguards are required to ensure safe adoption in healthcare.'}\n"
     ]
    }
   ],
   "source": [
    "# Display results from each task\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK OUTPUTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if hasattr(result, 'tasks_output') and result.tasks_output:\n",
    "    for i, task_output in enumerate(result.tasks_output, 1):\n",
    "        print(f\"\\n--- Task {i} Output ---\")\n",
    "        print(task_output.raw_output)\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(\"\\nFinal Result:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Research summary saved to: ../research_summary.md\n"
     ]
    }
   ],
   "source": [
    "# result is a dict returned by run_research_workflow with keys: draft_summary, review, final_summary\n",
    "research_findings = result.get('initial_searches', [])\n",
    "final_summary = result.get('final_summary', '')\n",
    "review_feedback = result.get('review', {})\n",
    "\n",
    "# Save to file\n",
    "output_file = \"../research_summary.md\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(final_summary)\n",
    "\n",
    "print(f\"‚úì Research summary saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Final Summary\n",
    "\n",
    "Let's display the final research summary in a nicely formatted way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Feedback\n",
    "\n",
    "Here's what the Reviewer Agent thought about the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REVIEWER FEEDBACK\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Reviewer Scores\n",
       "\n",
       "- **Coherence**: 4/5\n",
       "- **Factual_accuracy**: 3/5\n",
       "- **Structure**: 5/5\n",
       "- **Completeness**: 4/5\n",
       "- **Clarity**: 4/5\n",
       "\n",
       "_No suggestions provided._\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REVIEWER FEEDBACK\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if isinstance(review_feedback, dict):\n",
    "    md = \"### Reviewer Scores\\n\\n\"\n",
    "    scores = review_feedback.get('scores', {})\n",
    "    for k, v in scores.items():\n",
    "        md += f\"- **{k.capitalize()}**: {v}/5\\n\"\n",
    "    suggestions = review_feedback.get('suggestions', [])\n",
    "    if suggestions:\n",
    "        md += \"\\n### Suggestions\\n\\n\"\n",
    "        for s in suggestions:\n",
    "            md += f\"- {s}\\n\"\n",
    "    else:\n",
    "        md += \"\\n_No suggestions provided._\\n\"\n",
    "    display(Markdown(md))\n",
    "else:\n",
    "    display(Markdown(str(review_feedback)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Use the Simplified Function\n",
    "\n",
    "You can also use the `run_research_workflow` function for a simpler one-line execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick execution with a different topic\n",
    "# Uncomment to try:\n",
    "\n",
    "# new_topic = \"Bias in Large Language Models\"\n",
    "# result = run_research_workflow(\n",
    "#     topic=new_topic,\n",
    "#     hf_token=HF_TOKEN,\n",
    "#     output_file=\"../research_summary_bias.md\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete multi-agent research workflow using:\n",
    "\n",
    "### Technologies Used ‚úì\n",
    "- **CrewAI** for multi-agent orchestration and communication cycles\n",
    "- **LangChain** for tool integration (DuckDuckGo search)\n",
    "- **Hugging Face Inference API** for all LLM operations (NO local LLMs)\n",
    "\n",
    "### Hugging Face Models Used ‚úì\n",
    "| Agent | Model | Purpose |\n",
    "|-------|-------|---------|\n",
    "| Researcher | `mistralai/Mistral-7B-Instruct-v0.2` | Reasoning and coordination |\n",
    "| Writer | `HuggingFaceH4/zephyr-7b-beta` | Summarization |\n",
    "| Reviewer | `mistralai/Mistral-7B-Instruct-v0.2` | Text analysis |\n",
    "\n",
    "### Agent Communication Workflow ‚úì\n",
    "The three agents successfully collaborated through defined communication cycles:\n",
    "1. **Researcher** ‚Üí performs web search ‚Üí returns snippets to Writer\n",
    "2. **Writer** ‚Üí generates first draft using Hugging Face API ‚Üí sends to Reviewer\n",
    "3. **Reviewer** ‚Üí critiques and provides feedback ‚Üí returned for refinement\n",
    "4. **Writer** ‚Üí finalizes Markdown report based on feedback\n",
    "\n",
    "### Final Deliverables ‚úì\n",
    "- **research_summary.md**: 500-word structured summary with:\n",
    "  - Introduction\n",
    "  - Key Findings\n",
    "  - Ethical & Technical Challenges\n",
    "  - Conclusion\n",
    "- **Reviewer feedback**: Coherence and factuality evaluation\n",
    "\n",
    "### Next Steps\n",
    "- Try different research topics (healthcare, education, climate, etc.)\n",
    "- Experiment with different Hugging Face models\n",
    "- Add more specialized agents for specific domains\n",
    "- Integrate additional search tools (Tavily, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
